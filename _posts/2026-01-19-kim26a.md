---
title: Analyzing Fairness of Neural Network Prediction via Counterfactual Dataset
  Generation
openreview: gVdQBlZ0Cj
abstract: "Interpreting the inference-time behavior of deep neural networks remains
  a challenging problem.  Existing approaches to counterfactual explanation typically
  ask: What is the closest alternative $\\textit{input}$ that would alter the modelâ€™s
  prediction in a desired way?\r In contrast, we explore $\\textbf{counterfactual
  datasets}$.  Rather than perturbing the input, our method efficiently finds the
  closest alternative $\\textit{training dataset}$, one that differs from the original
  dataset by changing a few labels.  Training a new model on this altered dataset
  can then lead to a different prediction of a given test instance.\r This perspective
  provides a new way to assess fairness by directly analyzing the influence of label
  bias on training and inference.  Our approach can be characterized as probing whether
  a given prediction depends on biased labels.\r Since exhaustively enumerating all
  possible alternate datasets is infeasible, we develop analysis techniques that trace
  how bias in the training data may propagate through the learning algorithm to the
  trained network.\r Our method heuristically ranks and modifies the labels of a bounded
  number of training examples to construct a counterfactual dataset, retrains the
  model, and checks whether its prediction on a chosen test case changes.\r We evaluate
  our approach on feedforward neural networks across over 1100 test cases from 7 widely-used
  fairness datasets.  Results show that it modifies only a small subset of training
  labels, highlighting its ability to pinpoint the critical training examples that
  drive prediction changes.\r Finally, we demonstrate how counterfactual training
  datasets reveal connections between training examples and test cases, offering an
  interpretable way to probe dataset bias."
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: kim26a
month: 0
tex_title: Analyzing Fairness of Neural Network Prediction via Counterfactual Dataset
  Generation
firstpage: 247
lastpage: 262
page: 247-262
order: 247
cycles: false
bibtex_author: Kim, Brian Hyeongseok and Mitchell, Jacqueline and Wang, Chao
author:
- given: Brian Hyeongseok
  family: Kim
- given: Jacqueline
  family: Mitchell
- given: Chao
  family: Wang
date: 2026-01-19
address:
container-title: Proceedings of the 7th Northern Lights Deep Learning Conference (NLDL)
volume: '307'
genre: inproceedings
issued:
  date-parts:
  - 2026
  - 1
  - 19
pdf: https://raw.githubusercontent.com/mlresearch/v307/main/assets/kim26a/kim26a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
