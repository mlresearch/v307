---
title: Assessing Explanation Fragility of SHAP using Counterfactuals
openreview: 44vMSJUmTi
abstract: 'Post-hoc explanations such as SHAP are increasingly used to justify machine
  learning predictions. Yet, these explanations can be fragile: small, realistic input
  perturbations can cause large shifts in the importance of attributed features. We
  present a multi-seed, distance-controlled *stability assessment* for SHAP-based
  model explanations. For each data instance, we use DiCE to generate plausible counterfactuals,
  pool across random seeds, deduplicate, and retain the $K$ nearest counterfactuals.
  Using a shared independent masker and the model s logit (raw margin), we measure
  per-feature attribution shifts and summarise instance-level instability. On four
  tabular fairness benchmark datasets, we apply our protocol to a logistic regression,
  a multilayer perceptron, and decision trees, including boosted and bagged versions.
  We report within-model group-wise explanation stability and examine which features
  most often drive the observed shifts. To contextualise our findings, we additionally
  report coverage, effective-$K$, distance-to-boundary, and outlier diagnostics. The
  protocol is model-agnostic yet practical for deep networks (batched inference, shared
  background), turning explanation variability into an actionable fairness assessment
  without altering trained models.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: kasbohrer26a
month: 0
tex_title: Assessing Explanation Fragility of {SHAP} using Counterfactuals
firstpage: 211
lastpage: 234
page: 211-234
order: 211
cycles: false
bibtex_author: K{\"a}sbohrer, Cornelia C. and Mair, Sebastian and Jiang, Lili
author:
- given: Cornelia C.
  family: KÃ¤sbohrer
- given: Sebastian
  family: Mair
- given: Lili
  family: Jiang
date: 2026-01-19
address:
container-title: Proceedings of the 7th Northern Lights Deep Learning Conference (NLDL)
volume: '307'
genre: inproceedings
issued:
  date-parts:
  - 2026
  - 1
  - 19
pdf: https://raw.githubusercontent.com/mlresearch/v307/main/assets/kasbohrer26a/kasbohrer26a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
