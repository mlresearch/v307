---
title: Explaining Latent Representations of Neural Networks with Archetypal Analysis
openreview: k4zOV54nP4
software: https://github.com/Wedenborg/Explaining-Latent-Representations-of-Neural-Networks-with-Archetypal-Analysis
abstract: We apply Archetypal Analysis to the latent spaces of trained neural networks,
  offering interpretable explanations of feature representations of neural networks
  without relying on user-defined corpora. Through layer-wise analyses of convolutional
  networks and vision transformers across multiple classification tasks, we demonstrate
  that archetypes are robust, dataset-independent, and provide intuitive insights
  into how models encode and transform information from layer to layer. Our approach
  enables global insights by characterizing the unique structure of the latent representation
  space of each layer, while also offering localized explanations of individual decisions
  as convex combinations of extreme points (i.e., archetypes).
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wedenborg26a
month: 0
tex_title: Explaining Latent Representations of Neural Networks with Archetypal Analysis
firstpage: 448
lastpage: 468
page: 448-468
order: 448
cycles: false
bibtex_author: Wedenborg, Anna Emilie Jennow and Dorszewski, Teresa and Hansen, Lars
  Kai and Wickstr{\o}m, Kristoffer Knutsen and M{\o}rup, Morten
author:
- given: Anna Emilie Jennow
  family: Wedenborg
- given: Teresa
  family: Dorszewski
- given: Lars Kai
  family: Hansen
- given: Kristoffer Knutsen
  family: Wickstrøm
- given: Morten
  family: Mørup
date: 2026-01-19
address:
container-title: Proceedings of the 7th Northern Lights Deep Learning Conference (NLDL)
volume: '307'
genre: inproceedings
issued:
  date-parts:
  - 2026
  - 1
  - 19
pdf: https://raw.githubusercontent.com/mlresearch/v307/main/assets/wedenborg26a/wedenborg26a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
